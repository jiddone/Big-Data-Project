
# ğŸ¦ Twitter Tracker

**Analisi dei Tweet nel periodo pre-elezioni USA 2020**  
Progetto sviluppato da: **Gianluca Ferrari**  

## ğŸ“„ Descrizione

Twitter Tracker Ã¨ un progetto di analisi dei dati pubblicati su Twitter durante il mese di ottobre 2020, in prossimitÃ  delle elezioni presidenziali USA. Lâ€™obiettivo Ã¨ estrarre insight dal comportamento degli utenti attraverso query, sentiment analysis, topic modeling e visualizzazioni interattive.

---

## ğŸ“Š Dataset

- **Dimensione**: 31,7 GB
- **Formato**: 31 file `.csv` (uno per ogni giorno di ottobre 2020)
- **Totale Tweet iniziali**: ~88 milioni  
- **Tweet dopo la pulizia**: ~83 milioni (rimozione del 4,81%)

### âœ¨ Attributi principali:
- `tweet_id`, `created_at`, `user_id_str`, `text`, `hashtags`, `retweet_count`, `favorite_count`, `retweeted`, `lang`, `place_name`, `screen_name`, ...

> Alcuni attributi (es. `location`, `place_lat`, `place_lon`) sono stati rimossi per inconsistenza o valore nullo.

---

## âš™ï¸ Stack Tecnologico

- **Python**
- **Apache Spark + PySpark**
- **NLTK + VADER** (Sentiment Analysis)
- **MLlib (Spark)** (Topic Modeling con LDA)
- **Streamlit** (Interfaccia utente)

---

## ğŸ” FunzionalitÃ 

### ğŸ“ˆ Query e Metriche
- Numero totale di tweet, utenti unici, hashtag
- Top 10 utenti per tweet, like, retweet, engagement
- Tweet per giorno, lingua, luogo
- Estrazione tweet per utente, parola chiave o hashtag

### ğŸ˜„ Sentiment Analysis
- Preprocessing: rimozione retweet, menzioni, URL, lowercasing
- Modello: `SentimentIntensityAnalyzer` di VADER
- Output: classificazione tweet come positivi, neutrali o negativi

### ğŸ§  Topic Modeling
- Preprocessing: filtraggio per lingua inglese, rimozione stopword, tokenizzazione
- Modello: LDA con 25 topic e 500.000 tweet randomici
- Output: distribuzione dei topic + top tweet rappresentativi

### ğŸ’» Interfaccia (Streamlit)
- Visualizzazione risultati di query, sentiment e topic
- I dati sono pre-processati e salvati in file intermedi

---

## ğŸš€ Avvio del progetto

1. Clona il repository  
   ```bash
   git clone https://github.com/tuo-username/twitter-tracker.git
   cd twitter-tracker
   ```

2. Installa le dipendenze  
   ```bash
   pip install -r requirements.txt
   ```

3. Avvia l'interfaccia Streamlit  
   ```bash
   streamlit run app.py
   ```

> âš ï¸ Il dataset completo non Ã¨ incluso nel repository per motivi di spazio. PuÃ² essere richiesto separatamente o simulato tramite subset.

---

## ğŸ“ Struttura del progetto

```text
twitter-tracker/
â”‚
â”œâ”€â”€ data/                  # File CSV intermedi
â”œâ”€â”€ notebooks/             # Notebook di analisi
â”œâ”€â”€ scripts/               # Script PySpark e NLP
â”œâ”€â”€ app.py                 # Applicazione Streamlit
â”œâ”€â”€ requirements.txt       # Dipendenze Python
â””â”€â”€ README.md              # Questo file
```

---

## ğŸ“œ Licenza

Questo progetto Ã¨ distribuito con licenza **MIT**. Vedi il file `LICENSE` per maggiori dettagli.

---

## ğŸ¤ Ringraziamenti

- NLTK & VADER team per gli strumenti NLP
- Apache Spark per lâ€™elaborazione distribuita
- Streamlit per la semplicitÃ  dellâ€™interfaccia

---

## ğŸ“¬ Contatti

Per domande o suggerimenti:

**Gianluca Ferrari**  
ğŸ“§ Email: gianlucaferrari2000@gmail.com
